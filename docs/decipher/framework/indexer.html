<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.8.1" />
<title>decipher.framework.indexer API documentation</title>
<meta name="description" content="" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src="https://cse.google.com/cse.js?cx=017837193012385208679:pey8ky8gdqw"></script>
<style>.gsc-control-cse {padding:0 !important;margin-top:1em}</style>
<style>.homelink{display:block;font-size:2em;font-weight:bold;color:#555;padding-bottom:.5em;border-bottom:1px solid silver}.homelink:hover{color:inherit}.homelink img{max-width:20%;max-height:5em;margin:auto;margin-bottom:.3em}</style>
<link rel="icon" href="https://upload.wikimedia.org/wikipedia/commons/6/61/Searchtool.svg">
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>decipher.framework.indexer</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/chiefsan/deCiPher/blob/c4ddeace7d1cdb139754478aa0e9415b06e073b4/decipher/framework/indexer.py#L0-L326" class="git-link">Browse git</a>
</summary>
<pre><code class="python">import sqlite3
import nltk
import string
from bs4 import BeautifulSoup
from os import listdir, sep
from os.path import join, isfile, exists
from time import time
from tabulate import tabulate
from collections import defaultdict
from sqlalchemy.orm import scoped_session, sessionmaker
from collections import defaultdict


def preprocess_text(content: str) -&gt; (list, list):
    &#34;&#34;&#34;
    Preprocesses the text.
    Performs stemming and tokenization. 
    Returns tokens without stopwords and their corresponding indices.
    &#34;&#34;&#34;

    # convert the entire content to lowercase
    content = content.lower()

    # tokenize using the function nltk.word_tokenize
    tokens = nltk.word_tokenize(content)

    # define the stopwords (not downloading it like normal using nltk.download
    # because there was an issue during heroku deployment (resolved now).
    # &#39;$&#39; and &#39;,&#39; are stopwords specifically in this domain (observed when viewing the database)
    stopwords = [
        &#34;i&#34;,
        &#34;me&#34;,
        &#34;my&#34;,
        &#34;myself&#34;,
        &#34;we&#34;,
        &#34;our&#34;,
        &#34;ours&#34;,
        &#34;ourselves&#34;,
        &#34;you&#34;,
        &#34;you&#39;re&#34;,
        &#34;you&#39;ve&#34;,
        &#34;you&#39;ll&#34;,
        &#34;you&#39;d&#34;,
        &#34;your&#34;,
        &#34;yours&#34;,
        &#34;yourself&#34;,
        &#34;yourselves&#34;,
        &#34;he&#34;,
        &#34;him&#34;,
        &#34;his&#34;,
        &#34;himself&#34;,
        &#34;she&#34;,
        &#34;she&#39;s&#34;,
        &#34;her&#34;,
        &#34;hers&#34;,
        &#34;herself&#34;,
        &#34;it&#34;,
        &#34;it&#39;s&#34;,
        &#34;its&#34;,
        &#34;itself&#34;,
        &#34;they&#34;,
        &#34;them&#34;,
        &#34;their&#34;,
        &#34;theirs&#34;,
        &#34;themselves&#34;,
        &#34;what&#34;,
        &#34;which&#34;,
        &#34;who&#34;,
        &#34;whom&#34;,
        &#34;this&#34;,
        &#34;that&#34;,
        &#34;that&#39;ll&#34;,
        &#34;these&#34;,
        &#34;those&#34;,
        &#34;am&#34;,
        &#34;is&#34;,
        &#34;are&#34;,
        &#34;was&#34;,
        &#34;were&#34;,
        &#34;be&#34;,
        &#34;been&#34;,
        &#34;being&#34;,
        &#34;have&#34;,
        &#34;has&#34;,
        &#34;had&#34;,
        &#34;having&#34;,
        &#34;do&#34;,
        &#34;does&#34;,
        &#34;did&#34;,
        &#34;doing&#34;,
        &#34;a&#34;,
        &#34;an&#34;,
        &#34;the&#34;,
        &#34;and&#34;,
        &#34;but&#34;,
        &#34;if&#34;,
        &#34;or&#34;,
        &#34;because&#34;,
        &#34;as&#34;,
        &#34;until&#34;,
        &#34;while&#34;,
        &#34;of&#34;,
        &#34;at&#34;,
        &#34;by&#34;,
        &#34;for&#34;,
        &#34;with&#34;,
        &#34;about&#34;,
        &#34;against&#34;,
        &#34;between&#34;,
        &#34;into&#34;,
        &#34;through&#34;,
        &#34;during&#34;,
        &#34;before&#34;,
        &#34;after&#34;,
        &#34;above&#34;,
        &#34;below&#34;,
        &#34;to&#34;,
        &#34;from&#34;,
        &#34;up&#34;,
        &#34;down&#34;,
        &#34;in&#34;,
        &#34;out&#34;,
        &#34;on&#34;,
        &#34;off&#34;,
        &#34;over&#34;,
        &#34;under&#34;,
        &#34;again&#34;,
        &#34;further&#34;,
        &#34;then&#34;,
        &#34;once&#34;,
        &#34;here&#34;,
        &#34;there&#34;,
        &#34;when&#34;,
        &#34;where&#34;,
        &#34;why&#34;,
        &#34;how&#34;,
        &#34;all&#34;,
        &#34;any&#34;,
        &#34;both&#34;,
        &#34;each&#34;,
        &#34;few&#34;,
        &#34;more&#34;,
        &#34;most&#34;,
        &#34;other&#34;,
        &#34;some&#34;,
        &#34;such&#34;,
        &#34;no&#34;,
        &#34;nor&#34;,
        &#34;not&#34;,
        &#34;only&#34;,
        &#34;own&#34;,
        &#34;same&#34;,
        &#34;so&#34;,
        &#34;than&#34;,
        &#34;too&#34;,
        &#34;very&#34;,
        &#34;s&#34;,
        &#34;t&#34;,
        &#34;can&#34;,
        &#34;will&#34;,
        &#34;just&#34;,
        &#34;don&#34;,
        &#34;don&#39;t&#34;,
        &#34;should&#34;,
        &#34;should&#39;ve&#34;,
        &#34;now&#34;,
        &#34;d&#34;,
        &#34;ll&#34;,
        &#34;m&#34;,
        &#34;o&#34;,
        &#34;re&#34;,
        &#34;ve&#34;,
        &#34;y&#34;,
        &#34;ain&#34;,
        &#34;aren&#34;,
        &#34;aren&#39;t&#34;,
        &#34;couldn&#34;,
        &#34;couldn&#39;t&#34;,
        &#34;didn&#34;,
        &#34;didn&#39;t&#34;,
        &#34;doesn&#34;,
        &#34;doesn&#39;t&#34;,
        &#34;hadn&#34;,
        &#34;hadn&#39;t&#34;,
        &#34;hasn&#34;,
        &#34;hasn&#39;t&#34;,
        &#34;haven&#34;,
        &#34;haven&#39;t&#34;,
        &#34;isn&#34;,
        &#34;isn&#39;t&#34;,
        &#34;ma&#34;,
        &#34;mightn&#34;,
        &#34;mightn&#39;t&#34;,
        &#34;mustn&#34;,
        &#34;mustn&#39;t&#34;,
        &#34;needn&#34;,
        &#34;needn&#39;t&#34;,
        &#34;shan&#34;,
        &#34;shan&#39;t&#34;,
        &#34;shouldn&#34;,
        &#34;shouldn&#39;t&#34;,
        &#34;wasn&#34;,
        &#34;wasn&#39;t&#34;,
        &#34;weren&#34;,
        &#34;weren&#39;t&#34;,
        &#34;won&#34;,
        &#34;won&#39;t&#34;,
        &#34;wouldn&#34;,
        &#34;wouldn&#39;t&#34;,
    ] + [&#34;,&#34;, &#34;$&#34;]

    # Use a masking technique to remove stopwords from tokens
    mask = list(map(lambda word: word not in stopwords, tokens))

    token_indices_no_stopwords = list(filter(lambda i: mask[i], range(len(tokens))))
    tokens_no_stopwords = [tokens[i] for i in token_indices_no_stopwords]

    # return tokens without stopwords and corresponding indices
    return tokens_no_stopwords, token_indices_no_stopwords


from ..framework.schema import engine, Problem, InvertedIndex, TermDictionary


def preprocess_problems(session=scoped_session(sessionmaker(bind=engine))) -&gt; None:
    &#34;&#34;&#34;
    Index the problems in the Problem table.
    &#34;&#34;&#34;
    for problem in session.query(Problem).all():
        print(problem.problem_id)

        # extract the textual matter in the problem
        textual_matter = problem.statement + problem.note + problem.title

        # preprocess the textual matter
        textual_matter, indices = preprocess_text(textual_matter)

        # update the problem length
        session.execute(
            &#39;UPDATE problem SET problem_length = &#34;&#39;
            + str(len(textual_matter))
            + &#39;&#34; WHERE problem_id = &#39;
            + &#39;&#34;&#39;
            + str(problem.problem_id)
            + &#39;&#34;&#39;
        )
        for term in textual_matter:

            # find the term id
            if len(session.query(TermDictionary).filter_by(term=term).all()) == 0:
                # if term id does not exist, generate new term id and update the db
                next_id = len(session.query(TermDictionary).all())
                term_dict_element = TermDictionary()
                term_dict_element.term = term
                current_term_id = term_dict_element.term_id = next_id
                session.add(term_dict_element)
                session.commit()
            else:
                current_term_id = (
                    session.query(TermDictionary).filter_by(term=term).all()[0].term_id
                )

            # retrieve the entry of the term in the inverted index
            query = (
                session.query(InvertedIndex).filter_by(term_id=current_term_id).all()
            )
            if len(query) == 0:
                # if term is not present in inverted index, create new element
                inverted_index_element = InvertedIndex()
                inverted_index_element.term_id = current_term_id
                inverted_index_element.posting_list = str(defaultdict(int)).replace(
                    &#34;&lt;class &#39;int&#39;&gt;&#34;, &#34;int&#34;
                )
                inverted_index_element.term_frequency = 0
                inverted_index_element.document_frequency = 0
                session.add(inverted_index_element)
                session.commit()

            # update term frequency
            term_frequency = int(
                session.query(InvertedIndex)
                .filter_by(term_id=current_term_id)
                .all()[0]
                .term_frequency
            )
            term_frequency += 1
            session.execute(
                &#39;UPDATE inverted_index SET term_frequency = &#34;&#39;
                + str(term_frequency)
                + &#39;&#34; WHERE term_id = &#39;
                + str(current_term_id)
            )

            # update posting list
            posting_list = eval(
                session.query(InvertedIndex)
                .filter_by(term_id=current_term_id)
                .all()[0]
                .posting_list
            )
            if posting_list[problem.problem_id] == 0:
                # update document frequency the first time the term is encountered in a specific document (problem)
                document_frequency = int(
                    session.query(InvertedIndex)
                    .filter_by(term_id=current_term_id)
                    .all()[0]
                    .document_frequency
                )
                document_frequency += 1
                session.execute(
                    &#39;UPDATE inverted_index SET document_frequency = &#34;&#39;
                    + str(document_frequency)
                    + &#39;&#34; WHERE term_id = &#39;
                    + str(current_term_id)
                )
                session.commit()

            # update the posting list
            posting_list[problem.problem_id] += 1
            session.execute(
                &#39;UPDATE inverted_index SET posting_list = &#34;&#39;
                + str(posting_list).replace(&#34;&lt;class &#39;int&#39;&gt;&#34;, &#34;int&#34;)
                + &#39;&#34; WHERE term_id = &#39;
                + str(current_term_id)
            )
            session.commit()
    session.commit()</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="decipher.framework.indexer.preprocess_problems"><code class="name flex">
<span>def <span class="ident">preprocess_problems</span></span>(<span>session=&lt;sqlalchemy.orm.scoping.scoped_session object&gt;) -> NoneType</span>
</code></dt>
<dd>
<div class="desc"><p>Index the problems in the Problem table.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/chiefsan/deCiPher/blob/c4ddeace7d1cdb139754478aa0e9415b06e073b4/decipher/framework/indexer.py#L225-L327" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def preprocess_problems(session=scoped_session(sessionmaker(bind=engine))) -&gt; None:
    &#34;&#34;&#34;
    Index the problems in the Problem table.
    &#34;&#34;&#34;
    for problem in session.query(Problem).all():
        print(problem.problem_id)

        # extract the textual matter in the problem
        textual_matter = problem.statement + problem.note + problem.title

        # preprocess the textual matter
        textual_matter, indices = preprocess_text(textual_matter)

        # update the problem length
        session.execute(
            &#39;UPDATE problem SET problem_length = &#34;&#39;
            + str(len(textual_matter))
            + &#39;&#34; WHERE problem_id = &#39;
            + &#39;&#34;&#39;
            + str(problem.problem_id)
            + &#39;&#34;&#39;
        )
        for term in textual_matter:

            # find the term id
            if len(session.query(TermDictionary).filter_by(term=term).all()) == 0:
                # if term id does not exist, generate new term id and update the db
                next_id = len(session.query(TermDictionary).all())
                term_dict_element = TermDictionary()
                term_dict_element.term = term
                current_term_id = term_dict_element.term_id = next_id
                session.add(term_dict_element)
                session.commit()
            else:
                current_term_id = (
                    session.query(TermDictionary).filter_by(term=term).all()[0].term_id
                )

            # retrieve the entry of the term in the inverted index
            query = (
                session.query(InvertedIndex).filter_by(term_id=current_term_id).all()
            )
            if len(query) == 0:
                # if term is not present in inverted index, create new element
                inverted_index_element = InvertedIndex()
                inverted_index_element.term_id = current_term_id
                inverted_index_element.posting_list = str(defaultdict(int)).replace(
                    &#34;&lt;class &#39;int&#39;&gt;&#34;, &#34;int&#34;
                )
                inverted_index_element.term_frequency = 0
                inverted_index_element.document_frequency = 0
                session.add(inverted_index_element)
                session.commit()

            # update term frequency
            term_frequency = int(
                session.query(InvertedIndex)
                .filter_by(term_id=current_term_id)
                .all()[0]
                .term_frequency
            )
            term_frequency += 1
            session.execute(
                &#39;UPDATE inverted_index SET term_frequency = &#34;&#39;
                + str(term_frequency)
                + &#39;&#34; WHERE term_id = &#39;
                + str(current_term_id)
            )

            # update posting list
            posting_list = eval(
                session.query(InvertedIndex)
                .filter_by(term_id=current_term_id)
                .all()[0]
                .posting_list
            )
            if posting_list[problem.problem_id] == 0:
                # update document frequency the first time the term is encountered in a specific document (problem)
                document_frequency = int(
                    session.query(InvertedIndex)
                    .filter_by(term_id=current_term_id)
                    .all()[0]
                    .document_frequency
                )
                document_frequency += 1
                session.execute(
                    &#39;UPDATE inverted_index SET document_frequency = &#34;&#39;
                    + str(document_frequency)
                    + &#39;&#34; WHERE term_id = &#39;
                    + str(current_term_id)
                )
                session.commit()

            # update the posting list
            posting_list[problem.problem_id] += 1
            session.execute(
                &#39;UPDATE inverted_index SET posting_list = &#34;&#39;
                + str(posting_list).replace(&#34;&lt;class &#39;int&#39;&gt;&#34;, &#34;int&#34;)
                + &#39;&#34; WHERE term_id = &#39;
                + str(current_term_id)
            )
            session.commit()
    session.commit()</code></pre>
</details>
</dd>
<dt id="decipher.framework.indexer.preprocess_text"><code class="name flex">
<span>def <span class="ident">preprocess_text</span></span>(<span>content: str) -> (<class 'list'>, <class 'list'>)</span>
</code></dt>
<dd>
<div class="desc"><p>Preprocesses the text.
Performs stemming and tokenization.
Returns tokens without stopwords and their corresponding indices.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/chiefsan/deCiPher/blob/c4ddeace7d1cdb139754478aa0e9415b06e073b4/decipher/framework/indexer.py#L14-L219" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def preprocess_text(content: str) -&gt; (list, list):
    &#34;&#34;&#34;
    Preprocesses the text.
    Performs stemming and tokenization. 
    Returns tokens without stopwords and their corresponding indices.
    &#34;&#34;&#34;

    # convert the entire content to lowercase
    content = content.lower()

    # tokenize using the function nltk.word_tokenize
    tokens = nltk.word_tokenize(content)

    # define the stopwords (not downloading it like normal using nltk.download
    # because there was an issue during heroku deployment (resolved now).
    # &#39;$&#39; and &#39;,&#39; are stopwords specifically in this domain (observed when viewing the database)
    stopwords = [
        &#34;i&#34;,
        &#34;me&#34;,
        &#34;my&#34;,
        &#34;myself&#34;,
        &#34;we&#34;,
        &#34;our&#34;,
        &#34;ours&#34;,
        &#34;ourselves&#34;,
        &#34;you&#34;,
        &#34;you&#39;re&#34;,
        &#34;you&#39;ve&#34;,
        &#34;you&#39;ll&#34;,
        &#34;you&#39;d&#34;,
        &#34;your&#34;,
        &#34;yours&#34;,
        &#34;yourself&#34;,
        &#34;yourselves&#34;,
        &#34;he&#34;,
        &#34;him&#34;,
        &#34;his&#34;,
        &#34;himself&#34;,
        &#34;she&#34;,
        &#34;she&#39;s&#34;,
        &#34;her&#34;,
        &#34;hers&#34;,
        &#34;herself&#34;,
        &#34;it&#34;,
        &#34;it&#39;s&#34;,
        &#34;its&#34;,
        &#34;itself&#34;,
        &#34;they&#34;,
        &#34;them&#34;,
        &#34;their&#34;,
        &#34;theirs&#34;,
        &#34;themselves&#34;,
        &#34;what&#34;,
        &#34;which&#34;,
        &#34;who&#34;,
        &#34;whom&#34;,
        &#34;this&#34;,
        &#34;that&#34;,
        &#34;that&#39;ll&#34;,
        &#34;these&#34;,
        &#34;those&#34;,
        &#34;am&#34;,
        &#34;is&#34;,
        &#34;are&#34;,
        &#34;was&#34;,
        &#34;were&#34;,
        &#34;be&#34;,
        &#34;been&#34;,
        &#34;being&#34;,
        &#34;have&#34;,
        &#34;has&#34;,
        &#34;had&#34;,
        &#34;having&#34;,
        &#34;do&#34;,
        &#34;does&#34;,
        &#34;did&#34;,
        &#34;doing&#34;,
        &#34;a&#34;,
        &#34;an&#34;,
        &#34;the&#34;,
        &#34;and&#34;,
        &#34;but&#34;,
        &#34;if&#34;,
        &#34;or&#34;,
        &#34;because&#34;,
        &#34;as&#34;,
        &#34;until&#34;,
        &#34;while&#34;,
        &#34;of&#34;,
        &#34;at&#34;,
        &#34;by&#34;,
        &#34;for&#34;,
        &#34;with&#34;,
        &#34;about&#34;,
        &#34;against&#34;,
        &#34;between&#34;,
        &#34;into&#34;,
        &#34;through&#34;,
        &#34;during&#34;,
        &#34;before&#34;,
        &#34;after&#34;,
        &#34;above&#34;,
        &#34;below&#34;,
        &#34;to&#34;,
        &#34;from&#34;,
        &#34;up&#34;,
        &#34;down&#34;,
        &#34;in&#34;,
        &#34;out&#34;,
        &#34;on&#34;,
        &#34;off&#34;,
        &#34;over&#34;,
        &#34;under&#34;,
        &#34;again&#34;,
        &#34;further&#34;,
        &#34;then&#34;,
        &#34;once&#34;,
        &#34;here&#34;,
        &#34;there&#34;,
        &#34;when&#34;,
        &#34;where&#34;,
        &#34;why&#34;,
        &#34;how&#34;,
        &#34;all&#34;,
        &#34;any&#34;,
        &#34;both&#34;,
        &#34;each&#34;,
        &#34;few&#34;,
        &#34;more&#34;,
        &#34;most&#34;,
        &#34;other&#34;,
        &#34;some&#34;,
        &#34;such&#34;,
        &#34;no&#34;,
        &#34;nor&#34;,
        &#34;not&#34;,
        &#34;only&#34;,
        &#34;own&#34;,
        &#34;same&#34;,
        &#34;so&#34;,
        &#34;than&#34;,
        &#34;too&#34;,
        &#34;very&#34;,
        &#34;s&#34;,
        &#34;t&#34;,
        &#34;can&#34;,
        &#34;will&#34;,
        &#34;just&#34;,
        &#34;don&#34;,
        &#34;don&#39;t&#34;,
        &#34;should&#34;,
        &#34;should&#39;ve&#34;,
        &#34;now&#34;,
        &#34;d&#34;,
        &#34;ll&#34;,
        &#34;m&#34;,
        &#34;o&#34;,
        &#34;re&#34;,
        &#34;ve&#34;,
        &#34;y&#34;,
        &#34;ain&#34;,
        &#34;aren&#34;,
        &#34;aren&#39;t&#34;,
        &#34;couldn&#34;,
        &#34;couldn&#39;t&#34;,
        &#34;didn&#34;,
        &#34;didn&#39;t&#34;,
        &#34;doesn&#34;,
        &#34;doesn&#39;t&#34;,
        &#34;hadn&#34;,
        &#34;hadn&#39;t&#34;,
        &#34;hasn&#34;,
        &#34;hasn&#39;t&#34;,
        &#34;haven&#34;,
        &#34;haven&#39;t&#34;,
        &#34;isn&#34;,
        &#34;isn&#39;t&#34;,
        &#34;ma&#34;,
        &#34;mightn&#34;,
        &#34;mightn&#39;t&#34;,
        &#34;mustn&#34;,
        &#34;mustn&#39;t&#34;,
        &#34;needn&#34;,
        &#34;needn&#39;t&#34;,
        &#34;shan&#34;,
        &#34;shan&#39;t&#34;,
        &#34;shouldn&#34;,
        &#34;shouldn&#39;t&#34;,
        &#34;wasn&#34;,
        &#34;wasn&#39;t&#34;,
        &#34;weren&#34;,
        &#34;weren&#39;t&#34;,
        &#34;won&#34;,
        &#34;won&#39;t&#34;,
        &#34;wouldn&#34;,
        &#34;wouldn&#39;t&#34;,
    ] + [&#34;,&#34;, &#34;$&#34;]

    # Use a masking technique to remove stopwords from tokens
    mask = list(map(lambda word: word not in stopwords, tokens))

    token_indices_no_stopwords = list(filter(lambda i: mask[i], range(len(tokens))))
    tokens_no_stopwords = [tokens[i] for i in token_indices_no_stopwords]

    # return tokens without stopwords and corresponding indices
    return tokens_no_stopwords, token_indices_no_stopwords</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<header>
<a class="homelink" rel="home" title="pdoc Home" href="https://chiefsan.github.io/deCiPher/">
<img src="https://upload.wikimedia.org/wikipedia/commons/6/61/Searchtool.svg" alt=""> deCiPher
</a>
</header>
<div class="gcse-search" style="height: 70px"
data-as_oq="site:chiefsan.github.io inurl:github.com/chiefsan/deCiPher"
data-gaCategoryParameter="decipher.framework.indexer">
</div>
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="decipher.framework" href="index.html">decipher.framework</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="decipher.framework.indexer.preprocess_problems" href="#decipher.framework.indexer.preprocess_problems">preprocess_problems</a></code></li>
<li><code><a title="decipher.framework.indexer.preprocess_text" href="#decipher.framework.indexer.preprocess_text">preprocess_text</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.8.1</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>